{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime-corejs2/regenerator\";\nimport _asyncToGenerator from \"@babel/runtime-corejs2/helpers/esm/asyncToGenerator\";\nvar _jsxFileName = \"/Users/lcopeland1/SANDBOX/scrapecity/components/Page.js\";\nimport React from \"react\";\nvar __jsx = React.createElement;\nimport { useEffect, useState } from 'react';\nimport { ScrapeProvider } from './ScrapeContext';\n\nfunction useScrapes() {\n  var _useState = useState({\n    twitter: [],\n    instagram: []\n  }),\n      scrapes = _useState[0],\n      setScrapes = _useState[1];\n\n  useEffect(function () {\n    _asyncToGenerator(\n    /*#__PURE__*/\n    _regeneratorRuntime.mark(function _callee() {\n      var res, data;\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              console.log('mounting or updating');\n              _context.next = 3;\n              return fetch('http://localhost:3000/data');\n\n            case 3:\n              res = _context.sent;\n              _context.next = 6;\n              return res.json();\n\n            case 6:\n              data = _context.sent;\n              console.log(data);\n              setScrapes(data);\n\n            case 9:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee);\n    }))();\n  }, []);\n  return scrapes;\n}\n\nexport default function Page(_ref2) {\n  var children = _ref2.children;\n  var scrapes = useScrapes();\n  return __jsx(ScrapeProvider, {\n    value: {\n      scrapes: scrapes\n    },\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 24\n    },\n    __self: this\n  }, __jsx(\"div\", {\n    className: \"page\",\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 29\n    },\n    __self: this\n  }, children));\n}","map":{"version":3,"sources":["/Users/lcopeland1/SANDBOX/scrapecity/components/Page.js"],"names":["useEffect","useState","ScrapeProvider","useScrapes","twitter","instagram","scrapes","setScrapes","console","log","fetch","res","json","data","Page","children"],"mappings":";;;;;AAAA,SAASA,SAAT,EAAoBC,QAApB,QAAoC,OAApC;AACA,SAASC,cAAT,QAA+B,iBAA/B;;AAEA,SAASC,UAAT,GAAsB;AAAA,kBACcF,QAAQ,CAAC;AACvCG,IAAAA,OAAO,EAAE,EAD8B;AAEvCC,IAAAA,SAAS,EAAE;AAF4B,GAAD,CADtB;AAAA,MACVC,OADU;AAAA,MACDC,UADC;;AAKlBP,EAAAA,SAAS,CAAC,YAAY;AACpB;AAAA;AAAA,6BAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AACCQ,cAAAA,OAAO,CAACC,GAAR,CAAY,sBAAZ;AADD;AAAA,qBAEmBC,KAAK,CAAC,4BAAD,CAFxB;;AAAA;AAEOC,cAAAA,GAFP;AAAA;AAAA,qBAGoBA,GAAG,CAACC,IAAJ,EAHpB;;AAAA;AAGOC,cAAAA,IAHP;AAICL,cAAAA,OAAO,CAACC,GAAR,CAAYI,IAAZ;AACAN,cAAAA,UAAU,CAACM,IAAD,CAAV;;AALD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAD;AAOD,GARQ,EAQN,EARM,CAAT;AASA,SAAOP,OAAP;AACH;;AAED,eAAe,SAASQ,IAAT,QAA4B;AAAA,MAAZC,QAAY,SAAZA,QAAY;AACzC,MAAMT,OAAO,GAAGH,UAAU,EAA1B;AACA,SACE,MAAC,cAAD;AACE,IAAA,KAAK,EAAE;AACLG,MAAAA,OAAO,EAAPA;AADK,KADT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAKE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACGS,QADH,CALF,CADF;AAWD","sourcesContent":["import { useEffect, useState } from 'react';\nimport { ScrapeProvider } from './ScrapeContext';\n\nfunction useScrapes() {\n    const [ scrapes, setScrapes ] = useState({\n      twitter: [],\n      instagram: [],\n    });\n    useEffect(function () {\n      (async () => {\n        console.log('mounting or updating');\n        const res = await fetch('http://localhost:3000/data');\n        const data = await res.json();\n        console.log(data);\n        setScrapes(data);\n      })();\n    }, []);\n    return scrapes;\n}\n\nexport default function Page({ children }) {\n  const scrapes = useScrapes();\n  return (\n    <ScrapeProvider\n      value={{\n        scrapes,\n      }}\n    >\n      <div className=\"page\">\n        {children}\n      </div>\n    </ScrapeProvider>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}